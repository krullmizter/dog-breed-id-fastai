{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "NzdHY9BuvZzt",
      "metadata": {
        "id": "NzdHY9BuvZzt"
      },
      "source": [
        "# Dog Breed Identification built with Fast.ai's CNN using transfer learning\n",
        "---\n",
        "## Description\n",
        "\n",
        "This notebook will take on a dog breed identification challenge by [Kaggle](https://www.kaggle.com/competitions/dog-breed-identification). The challenge uses the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/), which is a subset of the much larger [ImageNet dataset](https://www.image-net.org/). This notebook also serves as a technical guide, and specification for developing an open-source dog breed identification model using Python and [Fast.ai's](https://github.com/fastai/fastai) Convolutional Neural Network (CNN) with transfer learning.\n",
        "\n",
        "This notebook can of course be used with other datasets as well, feel free to modify the cells and code to fit your needs. This notebook servers as a guide and starting point for further development.\n",
        "\n",
        "This notebook additionally explores the concepts of exploratory data analysis (EDA), data augmentation, image pre-processing, comprehensive logging of training statistics, the usage of libraries such as pandas, numpy and matplotlib among others, and the process of exporting and importing a trained model.\n",
        "\n",
        "This project also serves as the technical foundation for my bachelor's thesis on dog breed identification. The aim of this notebook, as well as my thesis, is to evaluate the efficiency and accuracy of my model when compared to similar models trained on the Stanford Dogs Dataset.\n",
        "\n",
        "This notebook is quite extensively documented, and uses various comments, and text cells to explain the development process. This notebook is not as detailed as my thesis, but the combination of this notebook, and my thesis creates a unified \"guide\" to doing image classification using Fast.ai. Feel free to comment, critique, and create your own version of this notebook.\n",
        "\n",
        "[Link to Thesis]() üìñ\n",
        "\n",
        "[Link to Github repo](https://github.com/krullmizter/dog-breed-id-fastai)\n",
        "\n",
        "---\n",
        "## Goals\n",
        "\n",
        "The goal of an image classification problem is to minimize the loss. Loss refers to the measure of how well a model's predictions match the actual classes/labels of the training data. A lower loss value indicates that the model is more accurate at making predictions.\n",
        "\n",
        "Striving for a high level of accuracy is also key. Accuracy is measured by how well the trained model can correctly predict the classes of unseen new images.\n",
        "\n",
        "---\n",
        "## Structure\n",
        "\n",
        "This is a broad overview of the main table of contents of this notebook:\n",
        "1.   Installs, Imports & Settings\n",
        "2.   Load the dataset\n",
        "3.   EDA\n",
        "4.   Dataloader\n",
        "5.   Training\n",
        "6.   Logging\n",
        "7.   Post-Training Analysis\n",
        "8.   Predictions\n",
        "9.   Export\n",
        "10.  Import trained model\n",
        "---\n",
        "## Technical Specifications\n",
        "\n",
        "### Setup\n",
        "Begin by downloading or cloning this projects public repo [GitHub](https://github.com/krullmizter/dog-breed-id-fastai).\n",
        "\n",
        "You can download and use the base environment files: `environment.yaml`, `requirements.txt` for conda, and Python respectively. The files can be found in the [repo](https://github.com/krullmizter/dog-breed-id-fastai/tree/main/venv).\n",
        "\n",
        "In the chapter **Settings, Variables & Paths** there are several changeable variables that controls if certain cells will run or not. Go over them with care before doing any training or testing.\n",
        "\n",
        "### Dataset\n",
        "This notebook will automatically download the Stanford dataset from my personal Google Drive, via a public link. But if you prefer you can [download](https://www.kaggle.com/competitions/dog-breed-identification/data) the Stanford dataset as a `.zip` file from Kaggle (you need a free Kaggle account to be able to download the file). If you do download the `.zip` file yourself, or use a different dataset, be sure to upload the dataset `.zip` file to the root directory, and rename the file: `dataset.zip`.\n",
        "\n",
        "### Local Development\n",
        "This project uses a multitude of different packages, libraries and dependencies to make all the code in this notebook work. Both the base Anaconda `environment.yaml` and Python `requirements.txt` dependencies files can be found in the Github [repo](https://github.com/krullmizter/dog-breed-id-fastai/tree/main/venv).\n",
        "\n",
        "The Python dependencies are needed for both local development and everywhere else, like Google Colab, Kaggle and so on but the dependencies will be installed automatically in the **Installs & Imports** chapter using `pip`.\n",
        "\n",
        "If you run this notebook locally, I recommend using Jupyter Notebook like [Anaconda notebooks](https://anaconda.org/) and running the notebook with administrative privileges. Begin by creating a new conda environment and load the needed dependencies from the terminal:\n",
        "\n",
        "`conda env create -f environment.yaml` \n",
        "\n",
        "or create the new environment in the Anaconda navigator and import the `environment.yaml` file into your Anaconda navigator.\n",
        "\n",
        "#### Errors\n",
        "`PackagesNotFoundError`\n",
        "\n",
        "If your conda installation can't find a certain package to download, then a tip is to use the dependency name, and the `-c` flag to specify from what channel you wish to download the dependency from:\n",
        "\n",
        "`conda install fastai pytorch pytorch-cuda -c fastai -c pytorch -c nvidia`\n",
        "\n",
        "### Google Colab\n",
        "\n",
        "If you want an easy way to run this notebook, use cloud-hosted GPUs, and have an easy time with dependencies and packages, then I recommend [Google Colab](https://colab.research.google.com/). To get started upload the `main.ipynb` to Colab. You can also clone my repo, and upload it to your GitHub and load your own repo to Google Colab. \n",
        "\n",
        "### Training Folder\n",
        "When running this notebook, with either the `export_model` or `log` variable set to true in the settings cell, a directory called `trained` will be created, in the root folder. It will hold a `.json` file with the stats of the model's training since its first successful training run. This way, one can view the past training stats to help with tweaking the model further. The directory will also hold the exported trained model as a `.pkl` file. It will also hold the exported .pkl file.\n",
        "\n",
        "### My Development\n",
        "\n",
        "My training was computed locally on an RTX-3070 GPU using Anaconda, and online via [Google Colab](https://colab.research.google.com/).\n",
        "\n",
        "The main software and libraries I used (specified versions are not required):\n",
        "* Anaconda (1.11.1)\n",
        "    * Conda (23.3.1)\n",
        "* Python (3.10.9)\n",
        "    * pip (22.3.1)\n",
        "* PyTorch (2.0.0)\n",
        "    * PyTorch CUDA (11.7)\n",
        "* Fast.ai (2.7.12)\n",
        "\n",
        "---\n",
        "## TODO\n",
        "* View bounding boxes.\n",
        "* Hover effect over the second scatter plot.\n",
        "* Link to thesis when done.\n",
        "---\n",
        "\n",
        "## Copyright \n",
        "\n",
        "Copyright (C) 2023 Samuel Granvik\n",
        "\n",
        "This program is free software: you can redistribute it and/or modify\n",
        "it under the terms of the GNU General Public License as published by\n",
        "the Free Software Foundation, either version 3 of the License, or\n",
        "(at your option) any later version.\n",
        "\n",
        "This program is distributed in the hope that it will be useful,\n",
        "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "GNU General Public License for more details.\n",
        "\n",
        "You should have received a copy of the GNU General Public License\n",
        "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
        "\n",
        "---\n",
        "This code was created by Samuel Granvik. If you use or modify this code, please give attribution to Samuel Granvik. \n",
        "\n",
        "Links: [Email](samgran@outlook.com) | [GitHub](https://github.com/krullmizter/) | [LinkedIn](https://www.linkedin.com/in/samuel-granvik-93977013a/)\n",
        "\n",
        "---\n",
        "\n",
        "<p>My dog Laban ‚ù§Ô∏è</p>\n",
        "<img src='https://github.com/krullmizter/dog-breed-id-fastai/blob/main/laban.jpg?raw=1' width='10%' height='10%' >"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2qHge2TzaIab",
      "metadata": {
        "id": "2qHge2TzaIab"
      },
      "source": [
        "## Installs & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5485944f-8201-4518-8e32-6e1381e26a40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-08T09:04:45.079555Z",
          "iopub.status.busy": "2023-05-08T09:04:45.078981Z",
          "iopub.status.idle": "2023-05-08T09:05:05.502513Z",
          "shell.execute_reply": "2023-05-08T09:05:05.501189Z",
          "shell.execute_reply.started": "2023-05-08T09:04:45.079524Z"
        },
        "id": "5485944f-8201-4518-8e32-6e1381e26a40",
        "outputId": "8f4b56b1-3f7c-4f0f-c683-1e6959179669"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Checks the Python package manager, pips', requirements.txt file for all the necessary packages to install or update before importing them\n",
        "!pip install -r venv/requirements.txt\n",
        "\n",
        "try:\n",
        "  # Disable some annoying warnings\n",
        "  import warnings\n",
        "  warnings.filterwarnings('ignore', category=UserWarning) \n",
        "\n",
        "  import os # Let's us interact with the underlying OS\n",
        "  import csv\n",
        "  import json\n",
        "  import gdown # Download large files from Google Drive\n",
        "  import random # Random numbers\n",
        "  import hashlib # Create and use hashes\n",
        "  import datetime # Get date and time\n",
        "  import requests # Handles HTTP requests\n",
        "  import numpy as np # Math functions\n",
        "  import pandas as pd # Data analysis and manipulation\n",
        "  from bs4 import BeautifulSoup # Parse HTML\n",
        "  from datetime import datetime # Let's us use date and time\n",
        "  from matplotlib import pyplot as plt # Visualizations\n",
        "\n",
        "  from fastai import __version__\n",
        "  from fastai.vision.all import * # Computer vision\n",
        "  from fastai.metrics import error_rate, accuracy, F1Score # Additional metrics\n",
        "    \n",
        "  print('Imports complete.\\n')\n",
        "\n",
        "except ImportError as e:\n",
        "  print(f'Error importing one or more libraries: {e}\\n')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  gpu_name = torch.cuda.get_device_name(0)\n",
        "  gpu_mem  = torch.cuda.mem_get_info()\n",
        "\n",
        "  print('Using versions: \\nFastai v.', __version__, '\\nPyTorch v.', torch.__version__, '\\nCUDA v.', torch.version.cuda)\n",
        "  print(f'\\nGPU: {gpu_name}\\nGPU Memory: {gpu_mem[1] / 1024 / 1024 / 1024:.2f} GB')\n",
        "else:\n",
        "  print('Please install PyTorch CUDA, with GPU utilized the model will be faster.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "YBkXpu3YL-Yn",
      "metadata": {
        "id": "YBkXpu3YL-Yn"
      },
      "source": [
        "## Settings, Variables & Paths\n",
        "\n",
        "Go over this chapter before starting, pay attention to the settings variables and what they do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z2Qwia9idlht",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:05:05.505821Z",
          "iopub.status.busy": "2023-05-08T09:05:05.505137Z",
          "iopub.status.idle": "2023-05-08T09:05:05.582590Z",
          "shell.execute_reply": "2023-05-08T09:05:05.581659Z",
          "shell.execute_reply.started": "2023-05-08T09:05:05.505770Z"
        },
        "id": "z2Qwia9idlht"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "If you want to use your own dataset change the using_provided_dataset variable to False, and upload your dataset .zip file to the root folder and call it: dataset.zip\n",
        "If show_plots is set to true, then a plot of the images widths and heights will be displayed\n",
        "Log set to true will output training stats to the stats (.json) file\n",
        "If export_model is set to true, the code will export the trained model (.pkl) file to the trained directory\n",
        "If sub is set to true a submission.csv file will be created in the root dir. based on the test dataset\n",
        "If import_model is set to true the code will check if there is a .pkl to import either locally in the root dir. or via Google Drive\n",
        "\n",
        "Default variable boolean values: True, True, True, False, False, False\n",
        "'''\n",
        "\n",
        "using_provided_dataset, show_plots, log, export_model, sub, import_model = True, True, True, False, False, False\n",
        "\n",
        "# Automatic reloading, and inline plotting\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "# Frees up GPU memory not used by PyTorch or Fast.ai, does not affect the content of the tensors\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Paths \n",
        "\n",
        "# Directories\n",
        "base_dir    = os.getcwd()\n",
        "dataset_dir = os.path.join(base_dir, 'stanford-dogs-dataset')\n",
        "train_dir   = os.path.join(dataset_dir, 'train')\n",
        "test_dir    = os.path.join(dataset_dir, 'test')\n",
        "trained_dir = os.path.join(base_dir, 'trained')\n",
        "\n",
        "# Files\n",
        "dataset_zip      = os.path.join(base_dir, 'dataset.zip')\n",
        "stats_file        = os.path.join(trained_dir, 'trained_model_stats.json')\n",
        "trained_model    = os.path.join(trained_dir, 'trained_model.pkl')\n",
        "import_model_file = os.path.join(base_dir, 'trained_model_for_import.pkl')\n",
        "labels_file       = os.path.join(dataset_dir, 'labels.csv')\n",
        "sub_file          = os.path.join(base_dir, 'submission.csv')\n",
        "laban            = os.path.join(base_dir, 'laban.jpg')\n",
        "bernese          = os.path.join(base_dir, 'bernese.jpg')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "u1P33zfoaRwX",
      "metadata": {
        "id": "u1P33zfoaRwX"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "This cell takes care of the loading of the dataset. By design this cell will download the Kaggle ```.zip``` file containing the Stanford Dog Breeds dataset from MY Google Drive.\n",
        "\n",
        "I host the ```.zip``` file publicly:\n",
        "https://drive.google.com/file/d/1fQY2bnPPyGw9xHURMJ-SVlYB8WYztixu/view?usp=sharing\n",
        "\n",
        "If you want to use your own dataset, just change the ```using_provided_dataset``` to ```False```, and upload your dataset as a ```.zip``` file to the root folder and call it ```dataset.zip```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olUfoDd74g6q",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:05:05.584179Z",
          "iopub.status.busy": "2023-05-08T09:05:05.583830Z",
          "iopub.status.idle": "2023-05-08T09:06:03.959216Z",
          "shell.execute_reply": "2023-05-08T09:06:03.957178Z",
          "shell.execute_reply.started": "2023-05-08T09:05:05.584141Z"
        },
        "id": "olUfoDd74g6q"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(dataset_dir):\n",
        "  if using_provided_dataset:\n",
        "    url = 'https://drive.google.com/u/0/uc?id=1fQY2bnPPyGw9xHURMJ-SVlYB8WYztixu'\n",
        "    output = dataset_zip\n",
        "    gdown.download(url, output, quiet=False)\n",
        "          \n",
        "  with zipfile.ZipFile(dataset_zip, 'r') as z:\n",
        "    z.extractall(dataset_dir)\n",
        "  z.close()\n",
        "\n",
        "  print(f'Unzipping: {dataset_zip}')\n",
        "        \n",
        "  print(f'\\nUnzipped the dataset, will remove {dataset_zip}')\n",
        "\n",
        "  os.remove(dataset_zip)\n",
        "    \n",
        "else:\n",
        "  print(f'{dataset_dir} already exists.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "83fda42f",
      "metadata": {
        "id": "83fda42f"
      },
      "source": [
        "## EDA - Exploratory Data Analysis\n",
        "\n",
        "EDA helps us view, and understand the data that we are working with. We can find patterns, relationships and other underlying meaningful information in the data. We also get a better understanding of how the data is structured and how to best use it. We also find errors, and other misconfigured data this way."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9bb7af19",
      "metadata": {
        "id": "9bb7af19"
      },
      "source": [
        "### EDA - Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tjqC5aRb_37p",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:03.962741Z",
          "iopub.status.busy": "2023-05-08T09:06:03.962315Z",
          "iopub.status.idle": "2023-05-08T09:06:04.053902Z",
          "shell.execute_reply": "2023-05-08T09:06:04.052905Z",
          "shell.execute_reply.started": "2023-05-08T09:06:03.962689Z"
        },
        "id": "tjqC5aRb_37p"
      },
      "outputs": [],
      "source": [
        "labels_df = pd.read_csv(os.path.join(dataset_dir, 'labels.csv'))\n",
        "\n",
        "print(f'Some basic info of the labels.\\n')\n",
        "display(labels_df.info())\n",
        "\n",
        "print('Shows us the labels.csv file, containing IDs for images, and their corresponding breed.')\n",
        "labels_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T_K8vQrgMKVC",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:04.055991Z",
          "iopub.status.busy": "2023-05-08T09:06:04.055579Z",
          "iopub.status.idle": "2023-05-08T09:06:04.125207Z",
          "shell.execute_reply": "2023-05-08T09:06:04.124159Z",
          "shell.execute_reply.started": "2023-05-08T09:06:04.055951Z"
        },
        "id": "T_K8vQrgMKVC"
      },
      "outputs": [],
      "source": [
        "print('The three breeds/classes with the most, and least amount of images.')\n",
        "\n",
        "amount_breed = labels_df.pivot_table(index='breed', aggfunc=len).rename(columns={'id': 'amount'})\n",
        "\n",
        "largest  = amount_breed.nlargest(3, 'amount')\n",
        "smallest = amount_breed.nsmallest(3, 'amount')\n",
        "\n",
        "pd.concat([largest, smallest])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4435852d",
      "metadata": {
        "id": "4435852d"
      },
      "source": [
        "### EDA - Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4749713",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:04.127110Z",
          "iopub.status.busy": "2023-05-08T09:06:04.126578Z",
          "iopub.status.idle": "2023-05-08T09:06:05.903163Z",
          "shell.execute_reply": "2023-05-08T09:06:05.902029Z",
          "shell.execute_reply.started": "2023-05-08T09:06:04.127057Z"
        },
        "id": "e4749713"
      },
      "outputs": [],
      "source": [
        "if show_plots:\n",
        "  # Analyze training images widths and heights\n",
        "  all_widths, all_heights, min_res_list, max_res_list = [], [], [], []\n",
        "\n",
        "  min_res_img, max_res_img = '', ''\n",
        "\n",
        "  min_pxs = float('inf')\n",
        "  max_pxs = float('-inf')\n",
        "    \n",
        "  # Loop over all images in the training dir. \n",
        "  for f in os.listdir(train_dir):\n",
        "    img_path = os.path.join(train_dir, f)\n",
        "        \n",
        "    # Add the resolution of each image to separate arrays of widths and heights\n",
        "    with Image.open(img_path) as img:\n",
        "      w, h = img.size\n",
        "        \n",
        "      all_widths.append(w)\n",
        "      all_heights.append(h)\n",
        "        \n",
        "      pxs = w * h\n",
        "            \n",
        "      # Check which image has the smallest and largest resolution\n",
        "      if pxs < min_pxs:\n",
        "        min_pxs = pxs\n",
        "        min_res_list = [w, h]\n",
        "        min_res_name = f\n",
        "      elif pxs > max_pxs:\n",
        "        max_pxs = pxs\n",
        "        max_res_list = [w, h]\n",
        "        max_res_name = f\n",
        "      img.close()\n",
        "            \n",
        "  print(f'Resolution Statistics:')\n",
        "  print(f'Average: { int(sum(all_widths) / len(all_widths)) }x{ int(sum(all_heights) / len(all_heights)) }px')\n",
        "  print(f'Smallest: {min_res_list[0]}x{min_res_list[1]}px ({min_res_name})')\n",
        "  print(f'Largest: {max_res_list[0]}x{max_res_list[1]}px ({max_res_name})')\n",
        "\n",
        "  # Plot the distributions of the training image's width and height on two scatter plots\n",
        "  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
        "\n",
        "  min_widths  = min(all_widths)+1\n",
        "  max_widths  = max(all_widths)+1\n",
        "  min_heights = min(all_heights)+1\n",
        "  max_heights = max(all_heights)+1\n",
        "\n",
        "  # Shows the entire training dataset distributions\n",
        "  ax1.scatter(all_widths, all_heights, alpha=0.25, s=3, color='green')\n",
        "  ax1.set_title('Distribution of the training images by resolution.')\n",
        "  ax1.set_xlabel('Width (px)')\n",
        "  ax1.set_xticks(np.arange(0, max_widths, 200))\n",
        "  ax1.set_ylabel('Height (px)')\n",
        "  ax1.set_yticks(np.arange(0, max_heights, 200))\n",
        "\n",
        "  # Shows a plot which is zoomed in on the more concentrated values\n",
        "  xmin, xmax, ymin, ymax = min_res_list[0], 750, min_res_list[1], 750\n",
        "  ax2.scatter(all_widths, all_heights, alpha=0.25, s=25, color='green')\n",
        "  ax2.set_xlim(xmin, xmax)\n",
        "  ax2.set_ylim(ymin, ymax)\n",
        "  ax2.set_title('Zoomed-in view of the distribution of the training images by resolution.')\n",
        "  ax2.set_xlabel('Width (px)')\n",
        "  ax2.set_xticks(np.arange(xmin, xmax+1, 25))\n",
        "  ax2.set_ylabel('Height (px)')\n",
        "  ax2.set_yticks(np.arange(ymin, ymax+1, 50))\n",
        "\n",
        "  plt.subplots_adjust(hspace=.25)\n",
        "  plt.show()\n",
        "else:\n",
        "  print('If you wish to show the plots, change the show_plots variable in the settings cell.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5e3f2276",
      "metadata": {
        "id": "5e3f2276"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "Ci8nTxcQEabF",
      "metadata": {
        "id": "Ci8nTxcQEabF"
      },
      "source": [
        "### Hyperparameters & Data Augmentation\n",
        "\n",
        "These are the most important parameters and settings you can change to tweak your model. The use of larger BS and pre-trained models will slow down the training, but they may also provide better results in terms of loss and accuracy. Tweak these settings, and the `tfms` variables to achieve your desired performance and output. Tip. Enable the logging of stats in the settings cell to easily keep track of what works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HTErouaJNmoe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:05.905459Z",
          "iopub.status.busy": "2023-05-08T09:06:05.904266Z",
          "iopub.status.idle": "2023-05-08T09:06:05.984890Z",
          "shell.execute_reply": "2023-05-08T09:06:05.983961Z",
          "shell.execute_reply.started": "2023-05-08T09:06:05.905419Z"
        },
        "id": "HTErouaJNmoe"
      },
      "outputs": [],
      "source": [
        "# Free up some GPU memory if possible\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "arch = convnext_large # Pre-trained model we train upon\n",
        "ep = 3 # One epoch refers to the entire training dataset being proceed one time in the neural network\n",
        "bs = 75 # Amount of images to feed in one batch to the neural network during one training iteration\n",
        "sz = 224 # The target size of each image that gets fed into the network\n",
        "opt_func = Adam # The optimization function to use, such as Adam, Ranger or SGD\n",
        "\n",
        "# Used to set the max split size (in MB) for the chunks of images that is used during training, this is done to lower the GPU memory usage\n",
        "max_split_size = 100\n",
        "\n",
        "'''\n",
        "We use transforms (tfms) to manipulate our data before training the model. The tfms are applied to the dataloader.\n",
        "\n",
        "item_tfms: A set amount of transformations applied to each image in the dataset to standardize the input images\n",
        "Resize is always needed to scale all input images to the same size, otherwise the data loading wont work\n",
        "\n",
        "batch_tfms: Transformations such as random noise or pixel value changes applied to a batch of images in the dataset\n",
        "The * is used to unpack a list or tuple. \n",
        "'''\n",
        " \n",
        "item_tfms = [\n",
        "    RandomResizedCrop(sz)\n",
        "]\n",
        "\n",
        "batch_tfms = [\n",
        "    *aug_transforms(size=sz), # The aug_transforms is a pre-defined list of transforms: flips, rotations, zooming, lighting among others\n",
        "    Normalize.from_stats(*imagenet_stats),\n",
        "]\n",
        "\n",
        "# Check if the Resize method is used, and if any transformations are being applied to the training data. This is used later in the stats file.\n",
        "if len(set(item_tfms)) > 1 or batch_tfms:\n",
        "  transforms = True\n",
        "else:\n",
        "  transforms = False\n",
        "\n",
        "print(f'Training will use: {ep} epochs, with a batch size of: {bs}, and the target size of each input image is: {sz}px. Applied transformations?: {transforms}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "23d1f48f",
      "metadata": {
        "id": "23d1f48f"
      },
      "source": [
        "### DataLoaders\n",
        "\n",
        "We use a DataLoaders or ```dls``` object to load our dataset, and also augment and pre-process the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mmVqqmDp6nO5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:05.986729Z",
          "iopub.status.busy": "2023-05-08T09:06:05.986406Z",
          "iopub.status.idle": "2023-05-08T09:06:09.365800Z",
          "shell.execute_reply": "2023-05-08T09:06:09.364661Z",
          "shell.execute_reply.started": "2023-05-08T09:06:05.986694Z"
        },
        "id": "mmVqqmDp6nO5"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "dls = ImageDataLoaders.from_csv(\n",
        "  path=dataset_dir,\n",
        "  folder='train',\n",
        "  test='test',\n",
        "  suff='.jpg',\n",
        "  size=sz,\n",
        "  bs=bs,\n",
        "  item_tfms=item_tfms, \n",
        "  batch_tfms=batch_tfms,\n",
        "  max_split_size_mb=max_split_size,\n",
        "  device = torch.device('cuda')\n",
        ")\n",
        "\n",
        "train_len = len(dls.train_ds)\n",
        "val_len   = len(dls.valid_ds)\n",
        "test_len  = len(os.listdir(test_dir))\n",
        "\n",
        "# Find the percentage of the valid. dataset \n",
        "val_pct = round((val_len / (val_len + train_len) * 100))\n",
        "\n",
        "print(f'Amount of images in each dataset\\nTotal: { (train_len + val_len) + test_len }\\n')\n",
        "print(f'Training: {train_len}\\nValidation: {val_len} ({val_pct}% of training dataset) \\nTestning: {test_len}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sHAHZDDySSSf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:09.368961Z",
          "iopub.status.busy": "2023-05-08T09:06:09.367896Z",
          "iopub.status.idle": "2023-05-08T09:06:09.415133Z",
          "shell.execute_reply": "2023-05-08T09:06:09.413943Z",
          "shell.execute_reply.started": "2023-05-08T09:06:09.368921Z"
        },
        "id": "sHAHZDDySSSf"
      },
      "outputs": [],
      "source": [
        "# Show some random training images and their corresponding labels\n",
        "dls.show_batch(max_n=3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "aa200432",
      "metadata": {
        "id": "aa200432"
      },
      "source": [
        "### Learner\n",
        "Here we create main training object a ```learner``` object to aid in setting up, pre-process, running the training loop\n",
        "\n",
        "The ```learner``` combines the previously created ```dls```, and our chosen pre-trained network, along with training metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fhjPY7igSVyy",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:09.420473Z",
          "iopub.status.busy": "2023-05-08T09:06:09.420073Z",
          "iopub.status.idle": "2023-05-08T09:06:31.961945Z",
          "shell.execute_reply": "2023-05-08T09:06:31.960732Z",
          "shell.execute_reply.started": "2023-05-08T09:06:09.420446Z"
        },
        "id": "fhjPY7igSVyy"
      },
      "outputs": [],
      "source": [
        "learner = cnn_learner(\n",
        "  dls,\n",
        "  arch,\n",
        "  metrics=[error_rate, accuracy]\n",
        ")\n",
        "\n",
        "learner.opt_func = opt_func\n",
        "\n",
        "print(f'Will use {arch.__name__}, and {learner.opt_func.__name__} as the optimization function.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H-YRbvzKy_Ni",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:31.963929Z",
          "iopub.status.busy": "2023-05-08T09:06:31.963551Z",
          "iopub.status.idle": "2023-05-08T09:06:32.012387Z",
          "shell.execute_reply": "2023-05-08T09:06:32.011138Z",
          "shell.execute_reply.started": "2023-05-08T09:06:31.963889Z"
        },
        "id": "H-YRbvzKy_Ni"
      },
      "outputs": [],
      "source": [
        "# This lets us view our models architecture, layers and our defined hyperparameters\n",
        "learner.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "aeaeecfb",
      "metadata": {
        "id": "aeaeecfb"
      },
      "source": [
        "### Learning Rate\n",
        "Learning rate is the step size used during the optimization of the training.\n",
        "\n",
        "In this cell we are trying to find the optimal learning rate using the method: ```lr_find()```.\n",
        "It increases the learning rate on a subset of training images until the loss diverges or the accuracy drops off.\n",
        "\n",
        "We want to use the ```.valley``` value for our base / suggested learning rate in later cells.\n",
        "lr later controls the step size of the gradient descent whilst training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b854c1ee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:06:32.014605Z",
          "iopub.status.busy": "2023-05-08T09:06:32.014120Z",
          "iopub.status.idle": "2023-05-08T09:08:20.824280Z",
          "shell.execute_reply": "2023-05-08T09:08:20.823109Z",
          "shell.execute_reply.started": "2023-05-08T09:06:32.014566Z"
        },
        "id": "b854c1ee"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "lr = learner.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
        "lr_sug = lr.valley\n",
        "lr_sug_ex = format(lr_sug, '.2e')\n",
        "\n",
        "print(f'Suggested lr: {lr_sug}, and its exponential notation: {lr_sug_ex}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4375802f",
      "metadata": {
        "id": "4375802f"
      },
      "source": [
        "### Fine Tuning (Transfer learning)\n",
        "The ```fine_tune()``` method allows us to train or fine-tune our model based on a pre-trained model with new data, i.e. transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7FSACRekYqiM",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-08T09:08:20.826386Z",
          "iopub.status.busy": "2023-05-08T09:08:20.825837Z",
          "iopub.status.idle": "2023-05-08T09:10:28.980796Z",
          "shell.execute_reply": "2023-05-08T09:10:28.978075Z",
          "shell.execute_reply.started": "2023-05-08T09:08:20.826337Z"
        },
        "id": "7FSACRekYqiM"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "'''\n",
        "fine_tune only works with the last layer of the pre-trained model, as the rest of the pre-trained layers are frozen. \n",
        "One could use the fit_one_cycle method, but it is more suited for training a model from scratch.\n",
        "'''\n",
        "\n",
        "print(f'Training with: {ep} epochs, with a learning rate of: {lr_sug_ex}\\n')\n",
        "\n",
        "# Start training timing\n",
        "start_time = datetime.now()\n",
        "\n",
        "# Train/Fine-tune\n",
        "learner.fine_tune(ep, lr_sug)\n",
        "\n",
        "# End training timing\n",
        "end_time = datetime.now()\n",
        "\n",
        "# Get the total training time in seconds\n",
        "total_seconds = int((end_time - start_time).total_seconds())\n",
        "\n",
        "# Compute hours, minutes, and seconds\n",
        "hr  = total_seconds // 3600\n",
        "min = (total_seconds % 3600) // 60\n",
        "sec = total_seconds % 60\n",
        "\n",
        "# Format the result to: hr:mm:sec\n",
        "training_time = f'{hr:02d}:{min:02d}:{sec:02d}'\n",
        "\n",
        "print(f'\\nFine-tuning (training) complete.\\nIt took: {training_time}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4f1296a6",
      "metadata": {
        "id": "4f1296a6"
      },
      "source": [
        "## Evaluation & Logging"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8I2amyAy3nXR",
      "metadata": {
        "id": "8I2amyAy3nXR"
      },
      "source": [
        "### Evaluate Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qvxDbq6u-73-",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.982504Z",
          "iopub.status.idle": "2023-05-08T09:10:28.983380Z",
          "shell.execute_reply": "2023-05-08T09:10:28.983150Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.983123Z"
        },
        "id": "qvxDbq6u-73-"
      },
      "outputs": [],
      "source": [
        "# The validate method is used to output the performance of the trained model against the validation dataset\n",
        "valid_metrics = learner.validate()\n",
        "\n",
        "# Convert the validation metrics to floating point numbers with two trailing decimal points, i.e. percentage values\n",
        "valid_metrics = [round(x*100, 2) for x in valid_metrics]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "s7FtlHPNkvPh",
      "metadata": {
        "id": "s7FtlHPNkvPh"
      },
      "source": [
        "We combine the validation metrics, hyperparameters, and additional metrics for the trained model in a single cell and save/log them into a ```.json``` file.\n",
        "\n",
        "This helps us gain a comprehensive understanding of the model's performance, preserve previous training statistics, and identify areas that require improvement.\n",
        "\n",
        "We utilize a hash function, that creates a hash based on all the changeable parameters like GPU, EP, BS, and Arch among others. The hash updates, if any of the parameters are changed.\n",
        "\n",
        "This approach enables us to check if the metrics we are attempting to append to the stats file already exist, thereby preventing duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i02yUeDAP7pE",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.984989Z",
          "iopub.status.idle": "2023-05-08T09:10:28.985822Z",
          "shell.execute_reply": "2023-05-08T09:10:28.985586Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.985560Z"
        },
        "id": "i02yUeDAP7pE"
      },
      "outputs": [],
      "source": [
        "if log:\n",
        "  # Get current date and time\n",
        "  now = datetime.now()\n",
        "  curr_time = now.strftime('%d/%m/%Y - %H:%M:%S')\n",
        "\n",
        "  # A list of additional metrics, and the hyperparameters used during training\n",
        "  add_metrics = [curr_time, training_time, arch.__name__, learner.opt_func.__name__,gpu_name, val_pct, ep, bs, sz, lr_sug_ex, transforms]\n",
        "\n",
        "  # Store both the additional and validation metrics in a single dataframe, with custom column names\n",
        "  trained_stats_df = pd.DataFrame([\n",
        "    add_metrics + valid_metrics], \n",
        "    columns=['Time Created', 'Training Time', 'Arch', 'Opt. Func.', 'GPU', 'Train/Val. Split(%)', 'EP', 'BS', 'SZ', 'LR', 'Transforms?', 'Loss(%)', 'Error(%)', 'Accuracy(%)'\n",
        "  ])\n",
        "        \n",
        "  # Convert the df to a JSON formatted string\n",
        "  trained_stats_json = trained_stats_df.to_json(orient='records', double_precision=2)\n",
        "\n",
        "  # Create a Python dictionary of the above created JSON string\n",
        "  trained_stats_dict = json.loads(trained_stats_json)\n",
        "\n",
        "  # Create the trained dir. if it doesn't exist\n",
        "  if not os.path.exists(trained_dir):\n",
        "    os.mkdir(trained_dir)\n",
        "    print(f'Created: {trained_dir}')\n",
        "\n",
        "  # Create a unique hash based on all the changeable parameters\n",
        "  hash_values = arch.__name__ + learner.opt_func.__name__ + gpu_name + str(val_pct) + str(ep) + str(bs) + str(sz) + lr_sug_ex + str(transforms)\n",
        "  curr_hash = hashlib.sha256(hash_values.encode('utf-8')).hexdigest()\n",
        "    \n",
        "  '''\n",
        "  If the stats file exists, and the current hash isn't in the JSON file, append the metrics to the stats file\n",
        "  If the stats file doesn't exist create it and add the metrics to the stats file\n",
        "  '''\n",
        "\n",
        "  if os.path.exists(stats_file):\n",
        "    with open(stats_file, 'r') as file_read:\n",
        "      stats_file_data = json.load(file_read)\n",
        "\n",
        "      if curr_hash in stats_file_data:\n",
        "        print('The metrics you are trying to append to the stats file already exist.')\n",
        "      else:\n",
        "        stats_file_data[curr_hash] = trained_stats_dict\n",
        "        file_read.close()\n",
        "\n",
        "        with open(stats_file, 'w') as file_write:\n",
        "          json.dump(stats_file_data, file_write, indent=2)\n",
        "        file_write.close()\n",
        "\n",
        "        print('Appended new metrics to the stats file.')\n",
        "  else:\n",
        "    with open(stats_file, 'w') as file_write:\n",
        "      json.dump({curr_hash: trained_stats_dict}, file_write, indent=2)\n",
        "    file_write.close()\n",
        "        \n",
        "    print(f'Created the stats file, and added the metrics to it.')\n",
        "else:\n",
        "  print('To log training stats, set the log variable in the settings cell to True.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "30cd4610",
      "metadata": {
        "id": "30cd4610"
      },
      "source": [
        "## Post Training Analysis\n",
        "\n",
        "Fast.ai contains some neat methods to visualize the trained models performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PfiqZJCnNrDi",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.989629Z",
          "iopub.status.idle": "2023-05-08T09:10:28.990464Z",
          "shell.execute_reply": "2023-05-08T09:10:28.990241Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.990215Z"
        },
        "id": "PfiqZJCnNrDi"
      },
      "outputs": [],
      "source": [
        "# Shows the steps, callbacks, and performance of the model during each training iteration\n",
        "learner.show_training_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FzU2cin0e0r8",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.991902Z",
          "iopub.status.idle": "2023-05-08T09:10:28.992746Z",
          "shell.execute_reply": "2023-05-08T09:10:28.992510Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.992485Z"
        },
        "id": "FzU2cin0e0r8"
      },
      "outputs": [],
      "source": [
        "# Show a random batch of images from the trained model\n",
        "learner.show_results(max_n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ubWn8zqHhOCW",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.994262Z",
          "iopub.status.idle": "2023-05-08T09:10:28.995121Z",
          "shell.execute_reply": "2023-05-08T09:10:28.994859Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.994834Z"
        },
        "id": "ubWn8zqHhOCW"
      },
      "outputs": [],
      "source": [
        "# Lets us view, interpret and analyze performance of our trained classification model\n",
        "interp = ClassificationInterpretation.from_learner(learner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bFwDRreKhraX",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.996578Z",
          "iopub.status.idle": "2023-05-08T09:10:28.997409Z",
          "shell.execute_reply": "2023-05-08T09:10:28.997182Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.997156Z"
        },
        "id": "bFwDRreKhraX"
      },
      "outputs": [],
      "source": [
        "# We plot a matrix that shows us the the distribution of correctly and incorrectly classified classes\n",
        "interp.plot_confusion_matrix(figsize=(15, 15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZP8CkOsNhVSL",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:28.998825Z",
          "iopub.status.idle": "2023-05-08T09:10:28.999650Z",
          "shell.execute_reply": "2023-05-08T09:10:28.999412Z",
          "shell.execute_reply.started": "2023-05-08T09:10:28.999387Z"
        },
        "id": "ZP8CkOsNhVSL"
      },
      "outputs": [],
      "source": [
        "# The 6 worst predicted images i.e. the images with highest losses\n",
        "interp.plot_top_losses(6, figsize=(15, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8tdI_deLhYV9",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.001110Z",
          "iopub.status.idle": "2023-05-08T09:10:29.001932Z",
          "shell.execute_reply": "2023-05-08T09:10:29.001687Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.001662Z"
        },
        "id": "8tdI_deLhYV9"
      },
      "outputs": [],
      "source": [
        "# Lets us view the most confused classes classed during training, and how many times they were wrongly predicted\n",
        "df = pd.DataFrame(data=interp.most_confused(min_val=5))\n",
        "df.columns = ['Predicted', 'Actual', 'Amount of wrong predictions']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sz1Or2FJWmkf",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.003413Z",
          "iopub.status.idle": "2023-05-08T09:10:29.004250Z",
          "shell.execute_reply": "2023-05-08T09:10:29.003998Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.003974Z"
        },
        "id": "Sz1Or2FJWmkf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We use the F1-score to measure the model's accuracy for both binary/single or multi-class classifications\n",
        "It uses a weighted average on the precision and recall of a trained model, F1-score = 2 * (precision * recall) / (precision + recall)\n",
        "F1-scores ranges between 0 - 1, 1 = perfect precision and recall, 0 = model is performing worse than random chance.\n",
        "'''\n",
        "\n",
        "interp.print_classification_report()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "caec3bac",
      "metadata": {
        "id": "caec3bac"
      },
      "source": [
        "## Predictions\n",
        "\n",
        "This chapter goes over the trained models performance, i.e. how well it predicts dog breeds on new unseen image. We will predict on single images and entire datasets."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "o46ShnSHpyow",
      "metadata": {
        "id": "o46ShnSHpyow"
      },
      "source": [
        "### Single Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zmotgYXNwbBJ",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.005703Z",
          "iopub.status.idle": "2023-05-08T09:10:29.006564Z",
          "shell.execute_reply": "2023-05-08T09:10:29.006337Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.006311Z"
        },
        "id": "zmotgYXNwbBJ"
      },
      "outputs": [],
      "source": [
        "# Here we have a function to predict the class and confidence on one image, based on a trained model, provided by a path\n",
        "def predict_img(img_path):\n",
        "  img = Image.open(img_path)\n",
        "  img_resized = img.resize((224, 224))\n",
        "  img_resized.show()\n",
        "  img.close()\n",
        "\n",
        "  pred_class, pred_idx, probs = learner.predict(img_resized)\n",
        "  conf = probs[pred_idx] * 100\n",
        "  print(f'\\nPredicted class: {pred_class.capitalize()}, confidence: {conf:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc490610",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.008029Z",
          "iopub.status.idle": "2023-05-08T09:10:29.008849Z",
          "shell.execute_reply": "2023-05-08T09:10:29.008616Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.008590Z"
        },
        "id": "dc490610"
      },
      "outputs": [],
      "source": [
        "# Choose a random unlabeled, unseen image from the test dataset for prediction\n",
        "predict_img(Path(test_dir).ls()[random.randint(0, test_len)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fdb64d",
      "metadata": {
        "id": "16fdb64d"
      },
      "outputs": [],
      "source": [
        "# Here we predict on an image of my dog Laban, who is a Labrador retriever\n",
        "predict_img(Path(laban))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ej4D3WyQwJcS",
      "metadata": {
        "id": "ej4D3WyQwJcS"
      },
      "outputs": [],
      "source": [
        "# We also evaluate on one more dog breed. A Bernese mountain dog\n",
        "predict_img(Path(bernese))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "BTVHBh56rbUI",
      "metadata": {
        "id": "BTVHBh56rbUI"
      },
      "source": [
        "### Random Google Dog Image\n",
        "\n",
        "This is a method that lets us use the BeautifulSoup and HTTP response libraries to search and download a random dog breed images from Google, and then predict the breed on the images we downloaded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40f8bee",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.010376Z",
          "iopub.status.idle": "2023-05-08T09:10:29.011252Z",
          "shell.execute_reply": "2023-05-08T09:10:29.010996Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.010968Z"
        },
        "id": "f40f8bee"
      },
      "outputs": [],
      "source": [
        "def rand_dog_image_pred():\n",
        "  from PIL import Image\n",
        "\n",
        "  url = 'https://www.google.com/search?q=dog&tbm=isch'\n",
        "  res = requests.get(url)\n",
        "    \n",
        "  # Parse the HTML content using BeautifulSoup\n",
        "  soup = BeautifulSoup(res.content, 'html.parser')\n",
        "    \n",
        "  # Fetch all image tags from the page\n",
        "  img_tags = soup.find_all('img')\n",
        "    \n",
        "  # Filter the image tags to only include ones with a src attribute\n",
        "  img_tags = [img for img in img_tags if 'src' in img.attrs]\n",
        "    \n",
        "  # Choose a random image\n",
        "  random_img_tag = random.choice(img_tags)\n",
        "\n",
        "  img_url = random_img_tag['src']\n",
        "    \n",
        "  # Do a HTTP request to get the image content\n",
        "  img_res = requests.get(img_url)\n",
        "\n",
        "  img_name = 'rand_dog.jpg'\n",
        "    \n",
        "  # Write the random dog image to a file named rand_dog in the root dir.\n",
        "  with open(img_name, 'wb') as f:\n",
        "    f.write(img_res.content)\n",
        "  f.close()\n",
        "        \n",
        "  print(f'Downloaded one random dog image from:\\n{img_url}\\n')\n",
        "\n",
        "  # Predict\n",
        "  predict_img(os.path.realpath(f.name))\n",
        "\n",
        "  # Remove the image after the prediction\n",
        "  os.remove(img_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b05e01",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.012690Z",
          "iopub.status.idle": "2023-05-08T09:10:29.013517Z",
          "shell.execute_reply": "2023-05-08T09:10:29.013285Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.013258Z"
        },
        "id": "43b05e01"
      },
      "outputs": [],
      "source": [
        "rand_dog_image_pred()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "WPK-X7Ggpyoy",
      "metadata": {
        "id": "WPK-X7Ggpyoy"
      },
      "source": [
        "### Entire Test Dataset\n",
        "Here we evaluate the predictions of our trained model on the entire test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bYkI6SRf8tAI",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.017342Z",
          "iopub.status.idle": "2023-05-08T09:10:29.018176Z",
          "shell.execute_reply": "2023-05-08T09:10:29.017923Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.017887Z"
        },
        "id": "bYkI6SRf8tAI"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We first need to list all the images file paths using get_image_files\n",
        "Then we create a test dataloader object and pass it to the get_preds method\n",
        "get_preds returns a tuple of predictions and targets/labels\n",
        "The test dataset contains no labels, hence we won't be using the second output\n",
        "'''\n",
        "\n",
        "# Get the paths to the test dataset images\n",
        "test_files = get_image_files(test_dir)\n",
        "\n",
        "# Create a test dataloader\n",
        "test_dl = dls.test_dl(test_files)\n",
        "\n",
        "# Get the predictions on the test dataloader\n",
        "preds, _ = learner.get_preds(dl=test_dl)\n",
        "\n",
        "# The shape of the prediction data, using the Standford dataset we can see that we have all the test images 10357, and 120 different classes/breeds\n",
        "print(preds.shape)\n",
        "\n",
        "# 120 predictions for each class/dog breed\n",
        "print(preds[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O9CuK6EkfDnI",
      "metadata": {
        "id": "O9CuK6EkfDnI"
      },
      "outputs": [],
      "source": [
        "# Here we load the labels.csv to a labels list and remove the first element which is the text: id, and breed.\n",
        "f = open(Path(labels_file), 'r')\n",
        "labels = list(csv.reader(f, delimiter=','))\n",
        "labels.pop(0)\n",
        "f.close()\n",
        "\n",
        "# This gets us the index of the highest probability class for each image\n",
        "pred_class_index = preds.argmax(dim=1)\n",
        "\n",
        "print(pred_class_index)\n",
        "\n",
        "# Map the highest class index to its corresponding label\n",
        "predicted_labels = [labels[i][1] for i in pred_class_index]\n",
        "\n",
        "print(predicted_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3UPc-Hwcxl4w",
      "metadata": {
        "id": "3UPc-Hwcxl4w"
      },
      "source": [
        "## Kaggle Submission\n",
        "\n",
        "Here is the cell that covers the creation of the submission file used for the Kaggle challenge. We use the cells from the above chapter to do this. For each image in the test dataset it will predict the probability of each class/breed. We finally create a submission.csv file if it doesn't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uIu7Vmic1bIs",
      "metadata": {
        "id": "uIu7Vmic1bIs"
      },
      "outputs": [],
      "source": [
        "if sub:\n",
        "  if not os.path.exists(sub_file):\n",
        "    submission = pd.DataFrame({'id':test_files.map(lambda x:x.stem)})\n",
        "    submission[list(dls.vocab)] = preds\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "  else:\n",
        "    print('Submission file already exists')\n",
        "else:\n",
        "  print('To create a submission file, set the sub variable in the settings cell to True.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "92da7c0b",
      "metadata": {
        "id": "92da7c0b"
      },
      "source": [
        "## Export Trained Model\n",
        "Exports the trained model as a ```.pkl``` file in the trained directory\n",
        "\n",
        "This ```.pkl``` file can be used to predict new images. The exported ```.pkl``` file can't be used to develop the model further, it is just used for direct predictions not to be further developed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdfcafe8",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.019635Z",
          "iopub.status.idle": "2023-05-08T09:10:29.020477Z",
          "shell.execute_reply": "2023-05-08T09:10:29.020245Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.020219Z"
        },
        "id": "fdfcafe8"
      },
      "outputs": [],
      "source": [
        "if export_model:\n",
        "  learner.export(trained_model)\n",
        "  print(f'Exported trained model file {trained_model}')       \n",
        "else:\n",
        "  print('Didn\\'t export the trained model, change the export variable in the settings cell if you wish to export.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "-9YsNtVUO5xs",
      "metadata": {
        "id": "-9YsNtVUO5xs"
      },
      "source": [
        "## Import & Utilize Trained Model\n",
        "\n",
        "This cell covers the loading and usage of a trained model / exported ```.pkl``` file.\n",
        "\n",
        "You can choose to import the trained model locally from the root dir., or by using Google Drive to load the model.\n",
        "\n",
        "When you have the model imported you can choose to run certain cells from above, move them down, or just create new cells to continue working and analyzing the performance of the developed model. Importing the model substantially reduces the time to evaluate a model since you don't have to train or fine-tune one every time.\n",
        "\n",
        "When importing we will create a new ```learner``` object to work with, that holds the trained models data. You can however run any of the above cells to work with those cells, their data and variables that already has been created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mRnYNZ5tpyoz",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-08T09:10:29.022071Z",
          "iopub.status.idle": "2023-05-08T09:10:29.022904Z",
          "shell.execute_reply": "2023-05-08T09:10:29.022671Z",
          "shell.execute_reply.started": "2023-05-08T09:10:29.022645Z"
        },
        "id": "mRnYNZ5tpyoz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The images in the Path (laban, bernese) are just the images that I've used during my training and testing\n",
        "Tip. Colab can be a bit tricky when working with uploaded files, you can upload your files to Google Drive and use them from there\n",
        "'''\n",
        "\n",
        "if import_model:\n",
        "  from fastai.vision.all import *\n",
        "\n",
        "  def predict_img(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    img_resized = img.resize((224, 224))\n",
        "    img_resized.show()\n",
        "    img.close()\n",
        "\n",
        "    pred_class, pred_idx, probs = learner.predict(img_resized)\n",
        "    conf = probs[pred_idx] * 100\n",
        "    print(f'\\nPredicted class: {pred_class.capitalize()}, confidence: {conf:.2f}%')\n",
        "\n",
        "  # Remember to place the model .pkl file you want to import in the root directory and name it trained_model_for_import.pkl\n",
        "  if os.path.exists(import_model_file):\n",
        "    imported_learner = load_learner(trained_model, cpu=False)\n",
        "\n",
        "    predict_img(Path(laban))\n",
        "    predict_img(Path(bernese))\n",
        "  else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    learner = load_learner('/content/drive/MyDrive/trained_model.pkl', cpu=False)\n",
        "\n",
        "    predict_img(Path('/content/drive/MyDrive/laban.jpg'))\n",
        "    predict_img(Path('/content/drive/MyDrive/bernese.jpg'))\n",
        "else:\n",
        "  print('Didn\\'t import any model, change the import variable in the settings cell if you wish to import.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a65127d9a23779821ffc62332078916c6390278dccf6d7ecf4d19390dad2b41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
