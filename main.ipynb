{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "NzdHY9BuvZzt",
   "metadata": {
    "id": "NzdHY9BuvZzt"
   },
   "source": [
    "# Dog Breed Identification built with Fast.ai's CNN using transfer learning\n",
    "---\n",
    "## Description\n",
    "\n",
    "This project will take on a dog breed identification challenge by [Kaggle](https://www.kaggle.com/competitions/dog-breed-identification). The challenge uses the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/).\n",
    "\n",
    "This notebook will automatically download the Stanford dataset from my personal Google Drive, via a public link. But if you prefer you can [download](https://www.kaggle.com/competitions/dog-breed-identification/data) the dataset as a `.zip` file from Kaggle (you need a free Kaggle account to be able to download the file). If you do download the `.zip` file yourself, be sure to unzip the file in the repo's root dir., and rename the file: `stanford-dogs-dataset`\n",
    "\n",
    "This project employs Python and the [Fast.ai](https://github.com/fastai/fastai) library to create an image classification model that leverages transfer learning and a convolutional neural network (CNN) to accurately and efficiently identify dog breeds trained on the Stanford Dogs dataset.\n",
    "\n",
    "This project also serves as the technical foundation for my bachelor's thesis on dog breed classification. The aim of this project, as well as my thesis, is to evaluate the efficiency and accuracy of my model when compared to similar models trained on the Standford Dogs Dataset.\n",
    "\n",
    "This notebook additionally explores the concepts of exploratory data analysis (EDA), data augmentation, image pre-processing among others.\n",
    "\n",
    "---\n",
    "## Goals\n",
    "\n",
    "The goal of an image classification problem is to minimize the loss. Loss refers to the measure of how well a model's predictions match the actual classes/labels of the training data. A lower loss value indicates that the model is more accurate at making predictions.\n",
    "\n",
    "Striving for a high level of accuracy is also key. Accuracy is measured by how well the trained model can correctly predict the classes of unseen new images.\n",
    "\n",
    "---\n",
    "## Structure\n",
    "\n",
    "This is a broad overview of the main table of contents of this notebook:\n",
    "1.   Installs, Imports & Settings\n",
    "2.   Load the dataset\n",
    "3.   EDA\n",
    "4.   Training\n",
    "5.   Dataloader\n",
    "6.   Logging\n",
    "7.   Post-Training Analysis\n",
    "8.   Predictions\n",
    "9.   Exports\n",
    "---\n",
    "## Technical Specifications\n",
    "\n",
    "Begin by downloading or cloning the repo [GitHub](https://github.com/krullmizter/dog-breed-id-fastai).\n",
    "\n",
    "### Local Development (Anaconda)\n",
    "\n",
    "If you run this notebook locally, I recommend using [Anaconda notebooks](https://anaconda.org/), creating a new enviroment, and running Anaconda with administrative privileges.\n",
    "\n",
    "You can download and use the base env. files: `environment.yaml`, `requirements.txt` for conda, and Python respectivly. The files can be found in the [repo](https://github.com/krullmizter/dog-breed-id-fastai/tree/main/venv).\n",
    "\n",
    "Create a conda env. from the terminal:\n",
    "`conda env create -f environment.yaml`, or import the `environment.yaml` file into your Anaconda navigator.\n",
    "\n",
    "Install all the base Python packages with pip:\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "#### Errors\n",
    "#### `PackagesNotFoundError`\n",
    "If your conda installation can't find a certain package to download, then a tip is to use the dependency name, and the `-c` flag to specify from what channel you wish to download the dependency from:\n",
    "\n",
    "`conda install fastai pytorch pytorch-cuda -c fastai -c pytorch -c nvidia`\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "If you want an easy way to run this notebook, use cloud-hosted GPUs, and have an easy time with dependencies and packages, then I recommend [Google Colab](https://colab.research.google.com/). To get started upload the `main.ipynb` to Colab.\n",
    "\n",
    "### Training Stats\n",
    "\n",
    "When running this notebook, a directory called `training` will be created, in the root folder. It will hold a `.json` file with the stats of the model's training since its first successful training run. This way, one can view the past training stats to help with tweaking the model further. The directory will also hold the exported trained model as a `.pkl` file.\n",
    "\n",
    "### Development\n",
    "\n",
    "My training was computed locally on an RTX-3070 GPU.\n",
    "\n",
    "The main software and libraries I used (specified versions are not required):\n",
    "* Anaconda (1.11.1)\n",
    "    * Conda (23.3.1)\n",
    "* Python (3.10.9)\n",
    "    * pip (22.3.1)\n",
    "* PyTorch (2.0.0)\n",
    "    * PyTorch CUDA (11.7)\n",
    "* Fast.ai (2.7.12)\n",
    "\n",
    "---\n",
    "## TODO\n",
    "* Better: `item_tfms` and `batch_tfms`.\n",
    "* Single or multi-item detection.\n",
    "* View bounding boxes.\n",
    "* Hover effect over the second scatter plot.\n",
    "* Link to thesis when done.\n",
    "* Publish code, choose a license.\n",
    "---\n",
    "Created by: Samuel Granvik [GitHub](https://github.com/krullmizter/) | [LinkedIn](https://www.linkedin.com/in/samuel-granvik-93977013a/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2qHge2TzaIab",
   "metadata": {
    "id": "2qHge2TzaIab"
   },
   "source": [
    "## Installs & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485944f-8201-4518-8e32-6e1381e26a40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5485944f-8201-4518-8e32-6e1381e26a40",
    "outputId": "db61cf3a-6059-4e4d-cfc0-538b4db5dc00"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore', category=UserWarning) \n",
    "\n",
    "    import re # RegEx\n",
    "    import os # Let's us interact with the underlying OS\n",
    "    import json\n",
    "    import random # Random numbers\n",
    "    import requests # Handles HTTP requests\n",
    "    import numpy as np # Math functions\n",
    "    import pandas as pd # Data analysis and manipulation\n",
    "    from bs4 import BeautifulSoup # Parse HTML\n",
    "    from datetime import datetime # Let's us use date and time\n",
    "    from matplotlib import pyplot as plt # Visualisations\n",
    "\n",
    "    from fastai import __version__\n",
    "    from fastai.vision.all import * # Computer vision\n",
    "    from fastai.metrics import error_rate, accuracy # Additional metrics\n",
    "    \n",
    "    print('Imports complete.\\n')\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f'Error importing one or more libraries: {e}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using versions: \\nFastai v.', __version__, '\\nPyTorch v.', torch.__version__, '\\nCUDA v.', torch.version.cuda)\n",
    "    print(f'\\nUsing GPU: {torch.cuda.get_device_name(0)}.')\n",
    "else:\n",
    "    print('Please install PyTorch CUDA, with GPU utilized the model will be faster.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YBkXpu3YL-Yn",
   "metadata": {
    "id": "YBkXpu3YL-Yn"
   },
   "source": [
    "## Settings & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2Qwia9idlht",
   "metadata": {
    "id": "z2Qwia9idlht"
   },
   "outputs": [],
   "source": [
    "# Settings, variables & paths\n",
    "\n",
    "'''\n",
    "If export_model is set to true, the code will export the trained model (.pkl) file to the trained directory\n",
    "If show_plots is set to true, then a plot of the images widths and heights will be displayed\n",
    "Log set to true will output training stats to the stats (.json) file\n",
    "\n",
    "Default settings: False, False, True\n",
    "'''\n",
    "\n",
    "export_model, show_plots, log = False, False, True\n",
    "\n",
    "# Automatic reloading, and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Frees up GPU memory not used by PyTorch or Fast.ai, does not affect the content of the tensors\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Paths \n",
    "\n",
    "# Directories\n",
    "base_dir    = os.getcwd()\n",
    "dataset_dir = os.path.join(base_dir, 'stanford-dogs-dataset')\n",
    "train_dir   = os.path.join(dataset_dir, 'train')\n",
    "test_dir    = os.path.join(dataset_dir, 'test')\n",
    "trained_dir = os.path.join(base_dir, 'trained')\n",
    "\n",
    "# Files\n",
    "dataset_zip   = os.path.join(base_dir, 'stanford-dogs-dataset.zip')\n",
    "trained_stats = os.path.join(trained_dir, 'trained_model_stats.json')\n",
    "trained_model = os.path.join(trained_dir, 'trained_model.pkl')\n",
    "sub_csv       = os.path.join(trained_dir, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u1P33zfoaRwX",
   "metadata": {
    "id": "u1P33zfoaRwX"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olUfoDd74g6q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "olUfoDd74g6q",
    "outputId": "d134fa3b-0d95-4945-ae8b-0978f7c0d951"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "This will download the Kaggle .zip file containing the Stanford Dog Breeds dataset from MY Google Drive. I host the .zip file publicly:\n",
    "https://drive.google.com/file/d/1fQY2bnPPyGw9xHURMJ-SVlYB8WYztixu/view?usp=sharing\n",
    "If you wish you can manualy provide the dataset. Just remember to place the folder in the root dir. and name the dataset folder: stanford-dogs-dataset\n",
    "'''\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "\n",
    "  import gdown\n",
    "\n",
    "  url = 'https://drive.google.com/u/0/uc?id=1fQY2bnPPyGw9xHURMJ-SVlYB8WYztixu'\n",
    "  output = dataset_zip\n",
    "  gdown.download(url, output, quiet=False)\n",
    "\n",
    "  print(f'Unzipping: {dataset_zip}')\n",
    "        \n",
    "  with zipfile.ZipFile(dataset_zip, 'r') as z:\n",
    "    z.extractall(dataset_dir)\n",
    "  z.close()\n",
    "        \n",
    "  print(f'\\nUnzipped the dataset, will remove {dataset_zip} afterwards.')\n",
    "\n",
    "  os.remove(dataset_zip)\n",
    "else:\n",
    "  print(f'{dataset_dir} already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fda42f",
   "metadata": {
    "id": "83fda42f"
   },
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7af19",
   "metadata": {
    "id": "9bb7af19"
   },
   "source": [
    "### EDA - Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tjqC5aRb_37p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "tjqC5aRb_37p",
    "outputId": "8cf10fb6-4025-4521-a093-72db0f68bc7d"
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(os.path.join(dataset_dir, 'labels.csv'))\n",
    "\n",
    "print(f'Some basic info of the labels.\\n')\n",
    "display(labels_df.info())\n",
    "\n",
    "print('Shows us the labels.csv file, containing IDs for images, and their corresponding breed.')\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T_K8vQrgMKVC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "T_K8vQrgMKVC",
    "outputId": "1cc8badf-032d-42f5-c56c-2fd102569104"
   },
   "outputs": [],
   "source": [
    "print('The three breeds/classes with the most, and least amount of images.')\n",
    "\n",
    "amount_breed = labels_df.pivot_table(index='breed', aggfunc=len).rename(columns={'id': 'amount'})\n",
    "\n",
    "largest  = amount_breed.nlargest(3, 'amount')\n",
    "smallest = amount_breed.nsmallest(3, 'amount')\n",
    "\n",
    "pd.concat([largest, smallest])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435852d",
   "metadata": {
    "id": "4435852d"
   },
   "source": [
    "### EDA - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4749713",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4749713",
    "outputId": "73303372-71fd-4998-9ac6-c7179bfda9bd"
   },
   "outputs": [],
   "source": [
    "if show_plots:\n",
    "    # Analyze training images widths and heights\n",
    "    all_widths, all_heights, min_res_list, max_res_list = [], [], [], []\n",
    "\n",
    "    min_res_img, max_res_img = '', ''\n",
    "\n",
    "    min_pxs = float('inf')\n",
    "    max_pxs = float('-inf')\n",
    "    \n",
    "    # Loop over all images in the training dir. \n",
    "    for f in os.listdir(train_dir):\n",
    "        img_path = os.path.join(train_dir, f)\n",
    "        \n",
    "        # Add the resolution of each image to separate arrays of widths and heights\n",
    "        with Image.open(img_path) as img:\n",
    "            w, h = img.size\n",
    "        \n",
    "            all_widths.append(w)\n",
    "            all_heights.append(h)\n",
    "        \n",
    "            pxs = w * h\n",
    "            \n",
    "            # Check which image has the smallest and largest resolution\n",
    "            if pxs < min_pxs:\n",
    "                min_pxs = pxs\n",
    "                min_res_list = [w, h]\n",
    "                min_res_name = f\n",
    "            elif pxs > max_pxs:\n",
    "                max_pxs = pxs\n",
    "                max_res_list = [w, h]\n",
    "                max_res_name = f\n",
    "        img.close()\n",
    "            \n",
    "    print(f'Resolution Statistics:')\n",
    "    print(f'Average: { int(sum(all_widths) / len(all_widths)) }x{ int(sum(all_heights) / len(all_heights)) }px')\n",
    "    print(f'Smallest: {min_res_list[0]}x{min_res_list[1]}px ({min_res_name})')\n",
    "    print(f'Largest: {max_res_list[0]}x{max_res_list[1]}px ({max_res_name})')\n",
    "\n",
    "    # Plot the distrubutions of the training image's width and height on two scatter plots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "    min_widths  = min(all_widths)+1\n",
    "    max_widths  = max(all_widths)+1\n",
    "    min_heights = min(all_heights)+1\n",
    "    max_heights = max(all_heights)+1\n",
    "\n",
    "    # Shows the entire training dataset distrubution\n",
    "    ax1.scatter(all_widths, all_heights, alpha=0.25, s=3, color='green')\n",
    "    ax1.set_title('Distribution of the training images by resolution.')\n",
    "    ax1.set_xlabel('Width (px)')\n",
    "    ax1.set_xticks(np.arange(0, max_widths, 200))\n",
    "    ax1.set_ylabel('Height (px)')\n",
    "    ax1.set_yticks(np.arange(0, max_heights, 200))\n",
    "\n",
    "    # Shows a plot which is zoomed in on the more concentrated values\n",
    "    xmin, xmax, ymin, ymax = min_res_list[0], 750, min_res_list[1], 750\n",
    "    ax2.scatter(all_widths, all_heights, alpha=0.25, s=25, color='green')\n",
    "    ax2.set_xlim(xmin, xmax)\n",
    "    ax2.set_ylim(ymin, ymax)\n",
    "    ax2.set_title('Zoomed-in view of the distribution of the training images by resolution.')\n",
    "    ax2.set_xlabel('Width (px)')\n",
    "    ax2.set_xticks(np.arange(xmin, xmax+1, 25))\n",
    "    ax2.set_ylabel('Height (px)')\n",
    "    ax2.set_yticks(np.arange(ymin, ymax+1, 50))\n",
    "\n",
    "    plt.subplots_adjust(hspace=.25)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('If you wish to show the plots, change the show_plots variable in the settings cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f2276",
   "metadata": {
    "id": "5e3f2276"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ci8nTxcQEabF",
   "metadata": {
    "id": "Ci8nTxcQEabF"
   },
   "source": [
    "### Hyperparameters & Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HTErouaJNmoe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTErouaJNmoe",
    "outputId": "e5a97c85-5acf-4b64-8433-f220b7f4671e"
   },
   "outputs": [],
   "source": [
    "# Free up some GPU memory if possible\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "arch = resnet101 # Pre-trained model we train upon\n",
    "ep = 1 # One epoch refers to the entire training dataset being proceced one time in the neural network\n",
    "bs = 32 # Amount of images to feed in one batch to the neural network during one training iteration\n",
    "sz = 224 # The target size of each image that gets fed into the network\n",
    "\n",
    "# A set amount of transformations applied to each image in the dataset to standardize the input images\n",
    "item_tfms = [Resize(sz)]\n",
    "\n",
    "# Transformations such as random noise or pixel value changes applied to a batch of images in the dataset\n",
    "batch_tfms = [\n",
    "    *aug_transforms(size=sz, max_warp=0), \n",
    "    Normalize.from_stats(*imagenet_stats)\n",
    "]\n",
    "\n",
    "print(f'Training will use: {ep} epochs, with a batch size of: {bs}, and the target size of each input image is: {sz}px.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d1f48f",
   "metadata": {
    "id": "23d1f48f"
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mmVqqmDp6nO5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmVqqmDp6nO5",
    "outputId": "1e3e4b68-9e35-426e-8fa3-08211e124007"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# We use a dataloader to load our dataset, and also augment and pre-process the data\n",
    "dls = ImageDataLoaders.from_csv(\n",
    "    path=dataset_dir,\n",
    "    folder='train',\n",
    "    test='test',\n",
    "    suff='.jpg',\n",
    "    size=sz,\n",
    "    bs=bs,\n",
    "    item_tfms=item_tfms, \n",
    "    batch_tfms=batch_tfms\n",
    ")\n",
    "\n",
    "train_len = len(dls.train_ds)\n",
    "val_len   = len(dls.valid_ds)\n",
    "test_len  = len(os.listdir(test_dir))\n",
    "\n",
    "print(f'Amount of images in each dataset\\nTotal: { (train_len + val_len) + test_len }.\\n')\n",
    "print(f'Train: {train_len}\\nValidation: {val_len} ({val_len/train_len:.0%} of train) \\nTest: {test_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sHAHZDDySSSf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "sHAHZDDySSSf",
    "outputId": "cbae17f5-6753-4a4c-aa37-bcbe9cbbb1ae"
   },
   "outputs": [],
   "source": [
    "# Show some random training images and their corresonding labels\n",
    "dls.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa200432",
   "metadata": {
    "id": "aa200432"
   },
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fhjPY7igSVyy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhjPY7igSVyy",
    "outputId": "d7ae5e87-d20d-4722-8e79-88b476c55da3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here we create main training object a learner object to aid in setting up, pre-process, running the training loop\n",
    "The learner combines the previously created dls, and our chosen pre-trained network, along with training metrics\n",
    "'''\n",
    "\n",
    "learner = cnn_learner(\n",
    "    dls,\n",
    "    arch,\n",
    "    metrics=[error_rate, accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H-YRbvzKy_Ni",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H-YRbvzKy_Ni",
    "outputId": "3a09a834-bfc6-4ed3-b23d-39bfd049c7dc"
   },
   "outputs": [],
   "source": [
    "# This lets us view our models architecture, layers and our defined hyperparameters\n",
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaeecfb",
   "metadata": {
    "id": "aeaeecfb"
   },
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854c1ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "b854c1ee",
    "outputId": "7bb4692e-46ce-4207-8630-72e28eff7a9c"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "'''\n",
    "In this cell we are trying to find the optimal learning rate (lr) using the method: lr_find()\n",
    "lr_find() increases the lr on a subset of training images until the loss diverges or the accuracy drops off\n",
    "We want to use the .valley value for our base / suggested learning rate in later cells\n",
    "lr later controls the step size of the gradient descent (GD) whilst training\n",
    "'''\n",
    "\n",
    "lr_optimal = learner.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_sug = lr_optimal.valley\n",
    "lr_sug_ex = format(lr_sug, '.2e')\n",
    "\n",
    "print(f'Suggested learning rate: {lr_sug}, and its exponential notation: {lr_sug_ex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375802f",
   "metadata": {
    "id": "4375802f"
   },
   "source": [
    "### Fine Tuning (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7FSACRekYqiM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "7FSACRekYqiM",
    "outputId": "b360ed84-33da-45f2-d26d-23197833c95a"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "'''\n",
    "The fine_tune method lets us train/fine-tune our model based on a pre-trained model, with new data\n",
    "fine_tune only works with the last layer of the pre-trained model, the rest of the pre-trained layers are frozen\n",
    "One could use the fit_one_cycle() method but it is more suited towards training a model from scratch\n",
    "'''\n",
    "\n",
    "print(f'Training with: {ep} epochs, with a learning rate of: {lr_sug_ex}\\n')\n",
    "\n",
    "# Start training timing\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train/Fine-tune\n",
    "learner.fine_tune(ep, lr_sug)\n",
    "\n",
    "# End training timing\n",
    "end_time = datetime.now()\n",
    "\n",
    "# Store the total training time as: hr:mm:sec\n",
    "training_time = end_time - start_time\n",
    "training_time = str(training_time).split('.')[0]\n",
    "\n",
    "print(f'\\nFine-tuning (training) complete.\\nIt took: {training_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1296a6",
   "metadata": {
    "id": "4f1296a6"
   },
   "source": [
    "## Evaluation & Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8I2amyAy3nXR",
   "metadata": {
    "id": "8I2amyAy3nXR"
   },
   "source": [
    "### Evaluate Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092385cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "092385cd",
    "outputId": "d1031b46-c4e4-4431-d6b0-9c4552c687b3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The validation method is used to evaluate the performance of the trained model against the validation dataset\n",
    "We are combining the training metrics, and the used hyperparameters for the model to log as a .json file\n",
    "We do this to get a better understanding of the trained model, store old training stats, and to better know what to tweak\n",
    "We are also converting any floating point numbers to percentage values\n",
    "'''\n",
    "\n",
    "if log:\n",
    "    \n",
    "    # Store the validation metrics\n",
    "    valid_metrics = learner.validate()\n",
    "    \n",
    "    deci_patt = r'^\\d+\\.\\d{3,}$'\n",
    "    \n",
    "    '''\n",
    "    Loop over the validation metrics\n",
    "    If a metric contains a decimal followd by more than two deciaml points\n",
    "    Turn the values from floating to % values, and only keep two trailning decimal points\n",
    "    '''\n",
    "    \n",
    "    for i, x in np.ndenumerate(valid_metrics):\n",
    "        if re.match(deci_patt, str(x)):\n",
    "            valid_metrics[i] = round((x * 100), 2)\n",
    "    \n",
    "    # Create a second array to store the used hyperparameters\n",
    "    parameters_arr = np.array([arch.__name__, ep, bs, lr_sug_ex, training_time])\n",
    "    \n",
    "    # Combine the two arrays into a data frame, and flip the initial col. and rows\n",
    "    df_trained_stats = pd.DataFrame(np.concatenate([valid_metrics, parameters_arr])).T\n",
    "    \n",
    "    # Update the df col. names\n",
    "    df_trained_stats.columns = ['Loss(%)', 'Error(%)', 'Accuracy(%)', 'Arch', 'EP', 'BS', 'LR', 'Time To Train']\n",
    "    \n",
    "    # In this part we are creating or updating a .json file with the df created above\n",
    "    \n",
    "    # Current time to add to each input\n",
    "    curr_time = datetime.now() \n",
    "    formatted_time = curr_time.strftime('%d/%m/%Y - %H:%M')\n",
    "\n",
    "    # Convert the eariler created df to .json, and convert any number represented as strings to floats\n",
    "    df_trained_stats[['Loss(%)', 'Error(%)', 'Accuracy(%)', 'EP', 'BS']] = df_trained_stats[['Loss(%)', 'Error(%)', 'Accuracy(%)', 'EP', 'BS']].astype(float)\n",
    "    trained_stats_json = df_trained_stats.to_json(orient='records')\n",
    "    \n",
    "    # Create a trained dir. if it doesn't exist\n",
    "    if not os.path.exists(trained_dir):\n",
    "        os.mkdir(trained_dir)\n",
    "        print(f'Created: {trained_dir}')\n",
    "        \n",
    "    # If the .json file exists, append new data to it, otherwise create the file and add the data to it\n",
    "    if os.path.exists(trained_stats): \n",
    "        with open(trained_stats, 'r') as f:\n",
    "            json_obj = json.load(f)\n",
    "            json_obj[formatted_time] = json.loads(trained_stats_json)\n",
    "            \n",
    "        f.close()\n",
    "            \n",
    "        # write the updated .json data back to the file\n",
    "        with open(trained_stats, 'w') as f:\n",
    "            json.dump(json_obj, f, indent=2)\n",
    "        f.close()\n",
    "            \n",
    "        print(f'Added new training stats data to: {trained_stats}')\n",
    "    else:   \n",
    "        json_obj = {formatted_time: json.loads(trained_stats_json)}\n",
    "        \n",
    "        with open(trained_stats, 'w') as f:\n",
    "            json.dump(json_obj, f, indent=2)\n",
    "        f.close()\n",
    "            \n",
    "        print(f'Created: {trained_stats}')\n",
    "else:\n",
    "    print('If you wish to store log, change the log variable in the settings cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gt-cWB-u3yyo",
   "metadata": {
    "id": "gt-cWB-u3yyo"
   },
   "source": [
    "### Evaluate Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9e869",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ccb9e869",
    "outputId": "ab2a5b74-ae4b-4d9b-e531-9c6634d53527"
   },
   "outputs": [],
   "source": [
    "# Here we use get_preds to test the trained model on a test dataset, contrary to the validate() method get_preds is testing on more 'real-world' data \n",
    "\n",
    "test_files = get_image_files(test_dir)\n",
    "\n",
    "# Create a test dataloader\n",
    "test_dl = dls.test_dl(test_files, bs=bs)\n",
    "\n",
    "# Get the predictions on the test dataloader\n",
    "preds, targs = learner.get_preds(dl=test_dl)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd4610",
   "metadata": {
    "id": "30cd4610"
   },
   "source": [
    "## Post Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PfiqZJCnNrDi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfiqZJCnNrDi",
    "outputId": "b58b73a6-97f6-4c73-a7f7-693990dec4c3"
   },
   "outputs": [],
   "source": [
    "# Shows the steps, callbacks, and performance of the model during each training iteration\n",
    "learner.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FzU2cin0e0r8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "FzU2cin0e0r8",
    "outputId": "d0d7b07d-7243-4138-cf5f-a5de640c5ac5"
   },
   "outputs": [],
   "source": [
    "# Show a random batch of images from the trained model\n",
    "learner.show_results(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ubWn8zqHhOCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ubWn8zqHhOCW",
    "outputId": "1db76ef3-27f8-4ca6-fa38-52da8153eeb9"
   },
   "outputs": [],
   "source": [
    "# Lets us view, interpret and analyze performance of our trained classification model\n",
    "interp = ClassificationInterpretation.from_learner(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bFwDRreKhraX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bFwDRreKhraX",
    "outputId": "5a0debff-81f0-4f04-e528-ba841e223cff"
   },
   "outputs": [],
   "source": [
    "# We plot a matrix that shows us the the distrubution of correctly and incorrectly classified classes\n",
    "interp.plot_confusion_matrix(figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZP8CkOsNhVSL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "ZP8CkOsNhVSL",
    "outputId": "36a019fd-6c85-4d19-e3ec-f291e1c93ef2"
   },
   "outputs": [],
   "source": [
    "# The 6 worst predicted images i.e. the images with highest losses\n",
    "interp.plot_top_losses(6, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8tdI_deLhYV9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8tdI_deLhYV9",
    "outputId": "3c5d8c6e-e49a-4832-9139-610f60617f97"
   },
   "outputs": [],
   "source": [
    "# Lets us view the most confused classes classed during training, and how many times they were wrongly predicted\n",
    "df = pd.DataFrame(data=interp.most_confused(min_val=5))\n",
    "df.columns = ['Predicted', 'Actual', 'Amount of wrong predictions']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec3bac",
   "metadata": {
    "id": "caec3bac"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmotgYXNwbBJ",
   "metadata": {
    "id": "zmotgYXNwbBJ"
   },
   "outputs": [],
   "source": [
    "# A function to predict the class and confidence, based on a trained model, of an image provided by a URL\n",
    "def predict_img(img):\n",
    "    print(img)\n",
    "    pred_class, pred_idx, probs = learner.predict(img)\n",
    "    conf = probs[pred_idx] * 100\n",
    "    print(f'Predicted class: {pred_class.capitalize()}, confidence: {conf:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc490610",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "dc490610",
    "outputId": "9db84970-9654-422c-9718-c7022e81d133"
   },
   "outputs": [],
   "source": [
    "# Choose an unlabeled, unseen image from the test dataset for prediction\n",
    "test_img = Path(test_dir).ls()[123]\n",
    "predict_img(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f8bee",
   "metadata": {
    "id": "f40f8bee"
   },
   "outputs": [],
   "source": [
    "# A function that lets us use the BeautifulSoup and HTTP response library to search and download a random dog image from Google\n",
    "def rand_dog_image_download():\n",
    "    url = 'https://www.google.com/search?q=dog&tbm=isch'\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    # Fetch all image tags from the page\n",
    "    img_tags = soup.find_all('img')\n",
    "    \n",
    "    # Filter the image tags to only include ones with a src attribute\n",
    "    img_tags = [img for img in img_tags if 'src' in img.attrs]\n",
    "    \n",
    "    # Choose a random image\n",
    "    random_img_tag = random.choice(img_tags)\n",
    "    \n",
    "    # Get the URL of the random image\n",
    "    img_url = random_img_tag['src']\n",
    "    \n",
    "    # Do a HTTP request to get the image content\n",
    "    img_res = requests.get(img_url)\n",
    "    \n",
    "    # Write the random dog image to a file named rand_dog in the root dir.\n",
    "    with open('rand_dog.jpg', 'wb') as f:\n",
    "        f.write(img_res.content)\n",
    "    f.close()\n",
    "        \n",
    "    print(f'Downloaded one random dog image from:\\n{img_url}\\n')\n",
    "    \n",
    "    # Predict\n",
    "    predict_img(os.path.realpath(f.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b05e01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "43b05e01",
    "outputId": "c79fc7f8-0201-4b78-b87b-d01dde60e415"
   },
   "outputs": [],
   "source": [
    "rand_dog_image_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da7c0b",
   "metadata": {
    "id": "92da7c0b"
   },
   "source": [
    "## Export Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfcafe8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdfcafe8",
    "outputId": "db01bd24-d2a2-41a1-aac0-96ff01ebdc6c"
   },
   "outputs": [],
   "source": [
    "# Exports the trained model as a .pki file in the trained directory\n",
    "if export_model:\n",
    "  learner.export(trained_model)\n",
    "  print(f'Exported trained model file {trained_model}')       \n",
    "else:\n",
    "    print('Didn\\'t export the trained model, change the export variable in the settings cell if you wish to export.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "caec3bac",
    "92da7c0b",
    "921ac2c3"
   ],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a65127d9a23779821ffc62332078916c6390278dccf6d7ecf4d19390dad2b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
